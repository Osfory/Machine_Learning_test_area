{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in Action!\n",
    "\n",
    "\n",
    "Предскажем цену съёмной квартиры в Нью-Йорке. Датасет: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data\n",
    "\n",
    "\n",
    "## 0. Описание задания \n",
    "\n",
    "Начнём наш крестовый поход за дешёвой недвижимостью с предобработки данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH = \"~/PycharmProjects/Datasets/\"\n",
    "hw = pd.read_csv(PATH + 'homework.txt', sep=\".\", encoding='CP1251') \n",
    "hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hw.iloc[9, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Предобработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd               \n",
    "import numpy as np                \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns             \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 8]\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Imports Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки: (48895, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/aleksey/PycharmProjects/Datasets/airbnb_ny/AB_NYC_2019.csv') \n",
    "print('Размер выборки:', df.shape)                         \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.889500e+04</td>\n",
       "      <td>4.889500e+04</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>38843.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.901714e+07</td>\n",
       "      <td>6.762001e+07</td>\n",
       "      <td>40.728949</td>\n",
       "      <td>-73.952170</td>\n",
       "      <td>152.720687</td>\n",
       "      <td>7.029962</td>\n",
       "      <td>23.274466</td>\n",
       "      <td>1.373221</td>\n",
       "      <td>7.143982</td>\n",
       "      <td>112.781327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098311e+07</td>\n",
       "      <td>7.861097e+07</td>\n",
       "      <td>0.054530</td>\n",
       "      <td>0.046157</td>\n",
       "      <td>240.154170</td>\n",
       "      <td>20.510550</td>\n",
       "      <td>44.550582</td>\n",
       "      <td>1.680442</td>\n",
       "      <td>32.952519</td>\n",
       "      <td>131.622289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.539000e+03</td>\n",
       "      <td>2.438000e+03</td>\n",
       "      <td>40.499790</td>\n",
       "      <td>-74.244420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.471945e+06</td>\n",
       "      <td>7.822033e+06</td>\n",
       "      <td>40.690100</td>\n",
       "      <td>-73.983070</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.967728e+07</td>\n",
       "      <td>3.079382e+07</td>\n",
       "      <td>40.723070</td>\n",
       "      <td>-73.955680</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.915218e+07</td>\n",
       "      <td>1.074344e+08</td>\n",
       "      <td>40.763115</td>\n",
       "      <td>-73.936275</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.648724e+07</td>\n",
       "      <td>2.743213e+08</td>\n",
       "      <td>40.913060</td>\n",
       "      <td>-73.712990</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       host_id      latitude     longitude         price  \\\n",
       "count  4.889500e+04  4.889500e+04  48895.000000  48895.000000  48895.000000   \n",
       "mean   1.901714e+07  6.762001e+07     40.728949    -73.952170    152.720687   \n",
       "std    1.098311e+07  7.861097e+07      0.054530      0.046157    240.154170   \n",
       "min    2.539000e+03  2.438000e+03     40.499790    -74.244420      0.000000   \n",
       "25%    9.471945e+06  7.822033e+06     40.690100    -73.983070     69.000000   \n",
       "50%    1.967728e+07  3.079382e+07     40.723070    -73.955680    106.000000   \n",
       "75%    2.915218e+07  1.074344e+08     40.763115    -73.936275    175.000000   \n",
       "max    3.648724e+07  2.743213e+08     40.913060    -73.712990  10000.000000   \n",
       "\n",
       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "count    48895.000000       48895.000000       38843.000000   \n",
       "mean         7.029962          23.274466           1.373221   \n",
       "std         20.510550          44.550582           1.680442   \n",
       "min          1.000000           0.000000           0.010000   \n",
       "25%          1.000000           1.000000           0.190000   \n",
       "50%          3.000000           5.000000           0.720000   \n",
       "75%          5.000000          24.000000           2.020000   \n",
       "max       1250.000000         629.000000          58.500000   \n",
       "\n",
       "       calculated_host_listings_count  availability_365  \n",
       "count                    48895.000000      48895.000000  \n",
       "mean                         7.143982        112.781327  \n",
       "std                         32.952519        131.622289  \n",
       "min                          1.000000          0.000000  \n",
       "25%                          1.000000          0.000000  \n",
       "50%                          1.000000         45.000000  \n",
       "75%                          2.000000        227.000000  \n",
       "max                        327.000000        365.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48895 entries, 0 to 48894\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              48895 non-null  int64  \n",
      " 1   name                            48879 non-null  object \n",
      " 2   host_id                         48895 non-null  int64  \n",
      " 3   host_name                       48874 non-null  object \n",
      " 4   neighbourhood_group             48895 non-null  object \n",
      " 5   neighbourhood                   48895 non-null  object \n",
      " 6   latitude                        48895 non-null  float64\n",
      " 7   longitude                       48895 non-null  float64\n",
      " 8   room_type                       48895 non-null  object \n",
      " 9   price                           48895 non-null  int64  \n",
      " 10  minimum_nights                  48895 non-null  int64  \n",
      " 11  number_of_reviews               48895 non-null  int64  \n",
      " 12  last_review                     38843 non-null  object \n",
      " 13  reviews_per_month               38843 non-null  float64\n",
      " 14  calculated_host_listings_count  48895 non-null  int64  \n",
      " 15  availability_365                48895 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Посмотрим на информацию по типам переменных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()  # посмотрим на то есть ли в переменных пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет. Это хорошая новость. Посмотрим как выглядит распределение цен. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.price.hist(bins=30);\n",
    "sns.histplot(df.price, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У распределения цен есть проблема - очень длинный хвост. Такой вид распределения называется логнормальным, поскольку если его прологарифмировато, то оно станет похоже на нормальное. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пути борьбы с выбросами: \n",
    "\n",
    "https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "\n",
    "https://medium.com/swlh/identify-outliers-with-pandas-statsmodels-and-seaborn-2766103bf67c\n",
    "\n",
    "https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из графика видно - у нас очень много выбросов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выборке встречаются квартиры с довольно большой стоимостью. Такие наблюдения называются выбросами. С ними нужно бороться, иначе наша модель подстроится под них, а это плохо. Проще говоря - модель переобучится. Сгладим распределение цен, прологарифмировав его. Так довольно часто поступают с целевой переменной. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.log(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df.price, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, y=df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на рспределение всех остальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('price',axis=1).hist(figsize=(20, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбросов в остальных данных не так уж и много. Значит можно использовать линейную регрессию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме гистограммок имеет смысл взглянуть на матрицу корреляций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(df.corr()[abs(df.corr()) > 0.5], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "cols = ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist', 'walk',\n",
    "       'brick', 'floor', 'code']\n",
    "\n",
    "for col in cols: \n",
    "    pearson_coef, p_value = stats.pearsonr(df[col], df['price'])\n",
    "    print(\"PearsonR между {} и price {} с p-значением pvalue = {}\".format(col, pearson_coef, p_value ))\n",
    "    \n",
    "    if p_value < 0.001:\n",
    "        print('Корреляция между {} и price статистически значимая'.format(col))\n",
    "    elif p_value < 0.05:\n",
    "        print('Корреляция между {} и price средняя'.format(col))\n",
    "    elif p_value < 0.1:\n",
    "        print('Корреляция между {} и price слабая'.format(col))\n",
    "    else:\n",
    "        print('Корреляция между {} и price статистически незначимая'.format(col))\n",
    "        \n",
    "    if pearson_coef > 0 :\n",
    "        if pearson_coef > 0.85:\n",
    "            print('Коэффициент ~{} показывает положительную очень сильную связь\\n'.format(pearson_coef))\n",
    "        elif pearson_coef > 0.75 :\n",
    "            print('Коэффициент ~{} показывает положительную достаточно сильную связь\\n'.format(pearson_coef))\n",
    "        elif pearson_coef > 0.60:\n",
    "            print('Коэффициент ~{} показывает положительную относительно сильную связь\\n'.format(pearson_coef))\n",
    "        elif pearson_coef > 0.50 :\n",
    "            print('Коэффициент ~{} показывает положительную среднюю связь\\n'.format(pearson_coef))\n",
    "        else:\n",
    "            print('Коэффициент ~{} показывает положительную слабую связь\\n'.format(pearson_coef))\n",
    "    else:\n",
    "        if abs(pearson_coef) > 0.85:\n",
    "            print('Коэффициент ~{} показывает негативную очень сильную связь\\n'.format(pearson_coef))\n",
    "        elif abs(pearson_coef) > 0.75 :\n",
    "            print('Коэффициент ~{} показывает негативную достаточно сильную связь\\n'.format(pearson_coef))\n",
    "        elif abs(pearson_coef) > 0.60:\n",
    "            print('Коэффициент ~{} показывает негативную относительно сильную связь\\n'.format(pearson_coef))\n",
    "        elif abs(pearson_coef) > 0.50 :\n",
    "            print('Коэффициент ~{} показывает негативную среднюю связь\\n'.format(pearson_coef))\n",
    "        else:\n",
    "            print('Коэффициент ~{} показывает негативную слабую связь\\n'.format(pearson_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чисто логически переменные metrdist и walk должны коррелировать, однако по расчётам этого не происходит. \n",
    "\n",
    "Для более адекватной оценки стоило бы группировать датасет по переменной walk, однако из-за того что ЛР является интерпертируемой моделью, то из результатов работы модели эти зависимости можно будет получить в явном виде. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно посмотрим на попарные диаграммы рассеивания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь распределение выглядит более приятно. \n",
    "\n",
    "Займёмся предобработкой категориальных переменных при помощи одного горячего кодирования (One Hot Encoding) (кек). При таком преобразовании категориальной переменной мы создаем столько новых столбцов, сколько различных значений этой переменной у нас было. Обычно, при этом, первый столбец убирается, чтобы не создавать линейно-зависимых столбцов. Например, если у переменной `\"погода\"` есть три состояния `\"хорошая\"`, `\"средняя\"` и `\"нормальная\"`, то после `OneHotEncoding` мы получим три столбца, где значения будут либо нулями, либо единицами, в зависимости от того, какая погода была в этом наблюдении.\n",
    "\n",
    "## Важно\n",
    "`OneHotEncoding` в общем случае тоже может привнести информацию о тестовой выборке в тренировочную в том случае, если в категориальном столбце в отложенной выборке могут содержаться новые значения. Если такая вероятность есть, то как и с другими методами препроцессинга, `OneHotEncoding` нужно обучать на трейне и использовать на тесте. \n",
    "\n",
    "В остальных случаях, можно воспользоваться удобной оберткой в `pandas` - `pd.get_dummies()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы не произошло утечки данных из трейна в тест, то стоит использовать OHE из sklearn'а.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# .fit на трейне, .transform на тесте!\n",
    "# .fit(train), .transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделали OHE для категориальной переменной\n",
    "df_categor = pd.get_dummies(df['code'], drop_first=True, prefix='code')\n",
    "# drop_first=True используется для того, чтобы избежать идеальной мультеколлинеарности в данных\n",
    "# Следовательно - использовать обязательно!\n",
    "\n",
    "# Объединили назад наши таблички\n",
    "df = pd.concat([df.drop('code',axis=1), df_categor], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим данные на тренировочные и тестовые! $30\\%$ данных откладываем для тестирования качества модели. Остальные $70\\%$ берём для обучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний предобрабатывательский штрих это скалирование (стандартизация непрерывных переменных). Вспомним зачем его делают. Обычно, когда обучают модель, хотят минимизировать ошибку, которую она допускает. Чаще всего эту функцию минимизируют численно. Если переменные измерены в разных шкалах (что-то в тоннах, что-то в годах и тд), алгоритм может при обучении заблудиться. Хорошо бы направить его и подтолкнуть в нужном направлении. Таким толчком является стандартизация переменных. \n",
    "\n",
    "Из каждой переменной вычетают среднее и делят на стандартное отклонение. Это очищает переменные от своих уникальных шкал и упрощает путь алгоритма к оптимальной точке. Обычно стандартное отклонение и среднее для скалирования оценивают на обучающей выборке. К тестовой применяют уже оценённый результат. Это позволяет не подглядывать в тестовую часть и не улучшать за счёт этого подглядывания прогнозы. Подглядывать - нечестно! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизация нужна и для корректного применения регуляризации в линейной регрессии, иначе будут большие штрафы за коэффициенты, а это ухудшает качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# объявили скалировщик!\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# учим скалировщик скалировать все переменны на трэйне\n",
    "scaler.fit(df_train.loc[:, ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем скалировщик к трэйну\n",
    "df_train_scale = scaler.transform(df_train.loc[:, ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist']])\n",
    "\n",
    "# Применяем скалирвощик к тесту \n",
    "df_test_scale = scaler.transform(df_test.loc[:, ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем значения на отскалированные\n",
    "df_train.loc[:, ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist']] = df_train_scale\n",
    "df_test.loc[:, ['totsp', 'livesp', 'kitsp', 'dist', 'metrdist']] = df_test_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все непрерывные переменные теперь выглядят проскалированными =) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape) # Посмотрим на размеры трэйна и теста \n",
    "print(df_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытаскиваем цены и параметры квартир по разным переменным для удобства \n",
    "\n",
    "y_train = df_train.price \n",
    "y_test = df_test.price \n",
    "\n",
    "X_train = df_train.drop('price', axis=1).to_numpy()\n",
    "X_test = df_test.drop('price', axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Константный прогноз "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаг первый. Построим константный прогноз. Будем говорить, что стоимость любой квартиры равна среднему значению. Это самый глупый прогноз, который мы можем сделать. Мы будем сравнивать с ним прогнозы более сложных моделей. Это бейзлайн-модель (baseline). Иногда, когда данные очень шумные, то она может быть лучше других моделей. Но это редкий вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(y_train)                     # посчитали среднее \n",
    "y_pred_naive = np.ones(len(y_test)) * y_mean  # спрогнозировали им цену всех квартир в тестовой выборке\n",
    "y_pred_naive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(y_pred_naive[:5]) # стоимости квартир в тыс. $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Метрики качества для регрессии \n",
    "\n",
    "Мы сделали выше прогноз. Теперь мы хотим понять насколько он хороший. Для этого обычно используют метрики. Посмотрим на несколько таких метрик. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics  # подгружаем метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой метрикой, с которой мы познакомимся, будет MAE (mean absolute error), средняя абсолютная ошибка. Она вычисляется следующим образом: \n",
    "\n",
    "$$ MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y}_i|. $$\n",
    "\n",
    "Если мы спрогнозировали, что квартира стоит 20 рублей, а она стоила 10 рублей, мы ошиблись на |10 - 20| = 10 рублей. Средняя абсолютная ошибка - это средняя сумма рублей, на которую мы облажались. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню, что мы прогнозируем логарифм цены, нам так удобнее. Ошибка выше считается в логарифмах. Если мы хотим посмотреть на ошибку в долларах, надо взять экспоненту от цен. Ниже мы можем увидеть, что в среднем ошибаемся на тридцать три с лишним тысячи долларов. (зависит от того как разобьётся датасет на тестовую и трейновую выборки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(np.exp(y_test), np.exp(y_pred_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй метрикой является MSE (mean squared error), средняя квадратичная ошибка. Она вычисляется как \n",
    "\n",
    "$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2.$$\n",
    "\n",
    "Смысл этой ошибки в том, чтобы штрафовать за большие ошибки сильнее, чем за маленькие. Если мы ошиблись на 5 долларов, то в ошибку войдёт 25. Если мы ошиблись на 10 долларов, то в ошибку войдёт 100. Чем выше ошибка, тем сильнее штраф. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии перейдём к долларам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(np.exp(y_test), np.exp(y_pred_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось многовато! Всё дело в том, что это не просто доллары, это квадратные доллары. Мы же суммировали квадраты. Неплохо было бы вернутся к обычным долларам. Для этого надо взять из MSE квадратный корень. Тогда получится новая ошибка, RMSE - Root Mean Squared Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(y_pred_naive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка в среднем более чем на 57 тысяч долларов. Так как более большие ошибки входят с более большим весом, вполне логично, что RMSE получилось больше, чем MAE. \n",
    "\n",
    "Часто для нас принципиальным является не то, на сколько денег мы ошиблись, а то на сколько процентов мы ошиблись. Метрика, которая отлавливает процентную ошибку, называется MAPE (mean absolute percentage error), средняя абсолютная процентная ошибка. \n",
    "\n",
    "$$\n",
    "MAPE = \\frac{1}{n} \\sum_{i=1}^n \\frac{|y_i - \\hat{y}_i|}{y_i}\n",
    "$$\n",
    "\n",
    "Она часто применяется в следующих задачах: например, вы прогнозируете спрос, и вам принципиально, на сколько процентов вы ошиблись, а не абсолютное значение. Если вы предсказали  один, а в реальности было  десять - это не то же самое, что вы предсказали  тысяча, а в реальности было  тысяча  девять. С точки зрения МАЕ или MSE, это две совершенно одинаковые ошибки. А если вас интересует, сколько в среднем на сколько процентов вы ошибаетесь, то это отражает МАРЕ.\n",
    "\n",
    "Её нам придётся реальзовать самостоятельно. Благо, это не очень трудно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "my_mean_absolute_percentage_error(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "mean_absolute_percentage_error(y_test, y_pred_naive) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя ошибка примерно на $5\\%$ от цены. \n",
    "\n",
    "Последняя метрика, с которой нам нужно познакомиться, это коэффициент детерминации, $R^2$. Он отражает то, какую долю дисперсии объясняемой переменной мы объяснили с помощью нашей модели:\n",
    "\n",
    "$$ R^2 =1- \\frac{ \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{ \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2} $$\n",
    "\n",
    "Эту метрику очень сильно любят консалтеры и аудиторы, потому что только её они и знают. На самом деле в ней нет ничего хорошего. При добавлении в модель новых переменных она всегда растёт. У неё есть ещё несколько тонких математических недостатков, о которых вы можете узнать из книг. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закинем все метрики в одну общую функцию, чтобы было удобно их печатать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test,y_pred):\n",
    "    print('MAE:', metrics.mean_absolute_error(np.exp(y_test), np.exp(y_pred)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('R2:',  metrics.r2_score(y_test, y_pred))\n",
    "    print('MAPE:', mean_absolute_percentage_error(y_test, y_pred) * 100)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Строим нашу первую регрессию!\n",
    "\n",
    "Пришло время построить линейную регрессию! Эта модель говорит, что цена на квартиру формируется в результате суммирования тех характеристик, которыми она обладает с какими-то весами\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + ... \\beta_n x_n.$$\n",
    "\n",
    "Например, если мы оценили модель и у нас получилось, что \n",
    "\n",
    "$$ price = 30 000 + 20 000 \\cdot totsp,$$\n",
    "\n",
    "то это означает, что средняя стоимость квартиры равна 30 тыс. долларам. При этом каждый дополнительный метр общей площади квартиры делает её дороже на 20 тысяч долларов. \n",
    "\n",
    "Для того, чтобы обучить регрессию минимизируют одну из метрик, перечисленных в прошлом разделе. В базовой комплектации регрессии это делают с MSE. Такая модель обладает огромным количеством няшных статистических свойств. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Объявили модель\n",
    "model_regression = LinearRegression()\n",
    "\n",
    "# Обучили модель на тренировочной выборке \n",
    "model_regression.fit(X_train, y_train)\n",
    "\n",
    "# Сделали прогнозы на тестовой выборке \n",
    "y_pred_regr = model_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество прогнозов. Мы стали ошибаться меньше, чем раньше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.intercept_, model_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие признаки вносят в цену наибольший вклад. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"feature\": df.drop('price',axis=1).columns, \n",
    "                                  \"importance\": model_regression.coef_})\n",
    "\n",
    "feature_importance.set_index('feature', inplace=True)\n",
    "feature_importance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=feature_importance, y=\"importance\", x=feature_importance.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Строим Lasso-регрессию "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим более сложную модель, LASSO-регрейссию. Фишка этой модели в том, что она зануляет лишние коэффиценты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Объявили модель\n",
    "model_simplelasso = Lasso()\n",
    "\n",
    "# Обучили модель на тренировочной выборке \n",
    "model_simplelasso.fit(X_train, y_train)\n",
    "\n",
    "# Сделали прогнозы на тестовой выборке \n",
    "y_pred_lasso = model_simplelasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на важность факторов для стоимости квартиры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"feature\": df.drop('price',axis=1).columns, \n",
    "                                  \"importance\": model_simplelasso.coef_})\n",
    "\n",
    "feature_importance.set_index('feature', inplace=True)\n",
    "feature_importance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=feature_importance, y=\"importance\", x=feature_importance.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важных факторов нет, всё занулилось. Метрики качества такие же, как при константном прогнозе. Почему такое произошло? Дело в том, что у модели есть гиперпараметр - сила зануления. И его нужно подбирать методом перебора. В нашей модели он стоял слишком большим. Давайте попробуем подобрать этот параметр. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Подбор гиперпараметра для Lasso-регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем делать перебор следующим способом: дробим тренировочную выборку на пять частей. На четырёх учим модель, на пятой прогнозируем. Смотрим на качество. И так по очереди выделяем для прогноза каждую из 5 частичек. Потом качество прогноза усредняем - кросс-валидация. Для какого параметра из решётки качетство получится наибольшим, тот мы и оставим. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Решётака для перебора параметра \n",
    "param_grid = {'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 0.8, 1]}\n",
    "\n",
    "# Объявили модель \n",
    "model_lasso = Lasso() \n",
    "\n",
    "# Объявили перебор \n",
    "grid_cv_lasso = GridSearchCV(model_lasso, param_grid, cv = 5)\n",
    "grid_cv_lasso.fit(X_train, y_train)\n",
    "print('Лучшее значение параметра:', grid_cv_lasso.best_params_)\n",
    "\n",
    "# Сделали прогнозы\n",
    "y_pred_lasso = grid_cv_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При параметре 0.001 качество у прогнозов получилось самым хорошим. Его и берём. Посмотрим на важность переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_lasso.best_estimator_.intercept_, grid_cv_lasso.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"feature\": df.drop('price',axis=1).columns, \n",
    "                                  \"importance\": grid_cv_lasso.best_estimator_.coef_})\n",
    "\n",
    "feature_importance.set_index('feature', inplace=True)\n",
    "feature_importance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=feature_importance, y=\"importance\", x=feature_importance.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на качество модели. Оно оказывается близким к обычной регрессии. Судя по всему у нас в выборке нет лишних переменных и занулять нечего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество квартир в районах\n",
    "df[[col for col in df.columns if \"code\" in col]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test,y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "lasso_cv = LassoCV(cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print('Лучшее значение параметра:', lasso_cv.alpha_)\n",
    "\n",
    "# Сделали прогнозы\n",
    "y_pred_lasso_cv = lasso_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"feature\": df.drop('price',axis=1).columns, \n",
    "                                  \"importance\": lasso_cv.coef_})\n",
    "\n",
    "feature_importance.set_index('feature', inplace=True)\n",
    "feature_importance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=feature_importance, y=\"importance\", x=feature_importance.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_lasso_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
